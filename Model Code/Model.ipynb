{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import ResNet50V2\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, BatchNormalization\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "base_dir = \"/content/drive/MyDrive/BTECHPROJ\"\n",
        "img_size = (224, 224)\n",
        "batch_size = 16\n",
        "num_classes = 3\n",
        "epochs = 40\n",
        "learning_rate = 2e-4  # Slightly higher for stronger warmup\n",
        "\n",
        "# Moderate augmentation for bacteria images\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    validation_split=0.2,\n",
        "    rotation_range=18,\n",
        "    width_shift_range=0.08,\n",
        "    height_shift_range=0.08,\n",
        "    brightness_range=[0.9, 1.12],\n",
        "    shear_range=0.09,\n",
        "    zoom_range=0.13,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    base_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    subset='training',\n",
        "    class_mode='categorical',\n",
        "    shuffle=True,\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    base_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    subset='validation',\n",
        "    class_mode='categorical',\n",
        "    shuffle=False,\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "# ResNet50V2 base model\n",
        "base_model = ResNet50V2(weights=\"imagenet\", include_top=False, input_shape=img_size + (3,))\n",
        "base_model.trainable = False\n",
        "\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.35)(x)\n",
        "x = Dense(384, activation='relu')(x)       # Slightly larger dense for more representation\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.25)(x)\n",
        "outputs = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=outputs)\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=learning_rate),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "callbacks = [\n",
        "    ModelCheckpoint(\n",
        "        filepath=\"/content/drive/MyDrive/BTECHPROJ/best_model.keras\",\n",
        "        monitor='val_accuracy',\n",
        "        save_best_only=True,\n",
        "        mode='max',\n",
        "        verbose=1\n",
        "    ),\n",
        "    EarlyStopping(\n",
        "        monitor='val_accuracy',\n",
        "        patience=7,\n",
        "        mode='max',\n",
        "        restore_best_weights=True,\n",
        "        verbose=1\n",
        "    ),\n",
        "    ReduceLROnPlateau(\n",
        "        monitor='val_loss',\n",
        "        factor=0.2,\n",
        "        patience=2,\n",
        "        min_lr=1e-6,\n",
        "        verbose=1\n",
        "    )\n",
        "]\n",
        "\n",
        "# Warmup: frozen base training\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=validation_generator,\n",
        "    epochs=epochs,\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Fine-tuning: unfreeze deeper layers (last 90 layers)\n",
        "base_model.trainable = True\n",
        "for layer in base_model.layers[:-90]:\n",
        "    layer.trainable = False\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=1e-5),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "fine_tune_epochs = 20\n",
        "total_epochs = epochs + fine_tune_epochs\n",
        "\n",
        "history_fine = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=validation_generator,\n",
        "    epochs=total_epochs,\n",
        "    initial_epoch=history.epoch[-1],\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Restore best weights for evaluation\n",
        "model.load_weights('/content/drive/MyDrive/BTECHPROJ/best_model.keras')\n",
        "val_loss, val_acc = model.evaluate(validation_generator, verbose=0)\n",
        "print(\"Training complete.\")\n",
        "print(f\"Best restored validation accuracy: {val_acc*100:.2f}%\")\n"
      ],
      "metadata": {
        "id": "eP4pphz3XXdb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed157f3d-c5b7-46a8-b9d2-dcbabbc669b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Found 254 images belonging to 3 classes.\n",
            "Found 63 images belonging to 3 classes.\n",
            "Epoch 1/40\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.4605 - loss: 1.4006\n",
            "Epoch 1: val_accuracy improved from -inf to 0.66667, saving model to /content/drive/MyDrive/BTECHPROJ/best_model.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 5s/step - accuracy: 0.4668 - loss: 1.3818 - val_accuracy: 0.6667 - val_loss: 0.7338 - learning_rate: 2.0000e-04\n",
            "Epoch 2/40\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.6900 - loss: 0.8116\n",
            "Epoch 2: val_accuracy improved from 0.66667 to 0.69841, saving model to /content/drive/MyDrive/BTECHPROJ/best_model.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 4s/step - accuracy: 0.6907 - loss: 0.8081 - val_accuracy: 0.6984 - val_loss: 0.6142 - learning_rate: 2.0000e-04\n",
            "Epoch 3/40\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.7543 - loss: 0.5284\n",
            "Epoch 3: val_accuracy improved from 0.69841 to 0.76190, saving model to /content/drive/MyDrive/BTECHPROJ/best_model.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 5s/step - accuracy: 0.7560 - loss: 0.5268 - val_accuracy: 0.7619 - val_loss: 0.5554 - learning_rate: 2.0000e-04\n",
            "Epoch 4/40\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.7616 - loss: 0.5796\n",
            "Epoch 4: val_accuracy improved from 0.76190 to 0.80952, saving model to /content/drive/MyDrive/BTECHPROJ/best_model.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 5s/step - accuracy: 0.7652 - loss: 0.5715 - val_accuracy: 0.8095 - val_loss: 0.4985 - learning_rate: 2.0000e-04\n",
            "Epoch 5/40\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.8326 - loss: 0.3773\n",
            "Epoch 5: val_accuracy improved from 0.80952 to 0.82540, saving model to /content/drive/MyDrive/BTECHPROJ/best_model.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 5s/step - accuracy: 0.8315 - loss: 0.3832 - val_accuracy: 0.8254 - val_loss: 0.5475 - learning_rate: 2.0000e-04\n",
            "Epoch 6/40\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9032 - loss: 0.2817\n",
            "Epoch 6: val_accuracy improved from 0.82540 to 0.84127, saving model to /content/drive/MyDrive/BTECHPROJ/best_model.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 4s/step - accuracy: 0.9012 - loss: 0.2882 - val_accuracy: 0.8413 - val_loss: 0.4815 - learning_rate: 2.0000e-04\n",
            "Epoch 7/40\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.8185 - loss: 0.4594\n",
            "Epoch 7: val_accuracy did not improve from 0.84127\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 5s/step - accuracy: 0.8190 - loss: 0.4569 - val_accuracy: 0.7937 - val_loss: 0.5587 - learning_rate: 2.0000e-04\n",
            "Epoch 8/40\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.8336 - loss: 0.3870\n",
            "Epoch 8: val_accuracy did not improve from 0.84127\n",
            "\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 3.9999998989515007e-05.\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 4s/step - accuracy: 0.8344 - loss: 0.3874 - val_accuracy: 0.7460 - val_loss: 0.6382 - learning_rate: 2.0000e-04\n",
            "Epoch 9/40\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.8373 - loss: 0.4047\n",
            "Epoch 9: val_accuracy did not improve from 0.84127\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 4s/step - accuracy: 0.8373 - loss: 0.4044 - val_accuracy: 0.7778 - val_loss: 0.5974 - learning_rate: 4.0000e-05\n",
            "Epoch 10/40\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.8880 - loss: 0.2839\n",
            "Epoch 10: val_accuracy did not improve from 0.84127\n",
            "\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 7.999999797903002e-06.\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 4s/step - accuracy: 0.8872 - loss: 0.2858 - val_accuracy: 0.8254 - val_loss: 0.6015 - learning_rate: 4.0000e-05\n",
            "Epoch 11/40\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.9099 - loss: 0.2653\n",
            "Epoch 11: val_accuracy did not improve from 0.84127\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 6s/step - accuracy: 0.9094 - loss: 0.2662 - val_accuracy: 0.8095 - val_loss: 0.5789 - learning_rate: 8.0000e-06\n",
            "Epoch 12/40\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.8658 - loss: 0.2549\n",
            "Epoch 12: val_accuracy did not improve from 0.84127\n",
            "\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 1.5999999959603884e-06.\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 4s/step - accuracy: 0.8658 - loss: 0.2564 - val_accuracy: 0.8254 - val_loss: 0.5336 - learning_rate: 8.0000e-06\n",
            "Epoch 13/40\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.8295 - loss: 0.4660\n",
            "Epoch 13: val_accuracy did not improve from 0.84127\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 4s/step - accuracy: 0.8312 - loss: 0.4596 - val_accuracy: 0.8095 - val_loss: 0.5322 - learning_rate: 1.6000e-06\n",
            "Epoch 13: early stopping\n",
            "Restoring model weights from the end of the best epoch: 6.\n",
            "Epoch 13/60\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.6535 - loss: 0.9190\n",
            "Epoch 13: val_accuracy did not improve from 0.84127\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 8s/step - accuracy: 0.6554 - loss: 0.9144 - val_accuracy: 0.7460 - val_loss: 0.5901 - learning_rate: 1.0000e-05\n",
            "Epoch 14/60\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.6955 - loss: 0.8997\n",
            "Epoch 14: val_accuracy did not improve from 0.84127\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 8s/step - accuracy: 0.6945 - loss: 0.8971 - val_accuracy: 0.7460 - val_loss: 0.5484 - learning_rate: 1.0000e-05\n",
            "Epoch 15/60\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.7216 - loss: 0.7343\n",
            "Epoch 15: val_accuracy did not improve from 0.84127\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 8s/step - accuracy: 0.7224 - loss: 0.7307 - val_accuracy: 0.7778 - val_loss: 0.5677 - learning_rate: 1.0000e-05\n",
            "Epoch 16/60\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.7651 - loss: 0.5571\n",
            "Epoch 16: val_accuracy did not improve from 0.84127\n",
            "\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 1.9999999494757505e-06.\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 8s/step - accuracy: 0.7666 - loss: 0.5549 - val_accuracy: 0.7937 - val_loss: 0.6242 - learning_rate: 1.0000e-05\n",
            "Epoch 17/60\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.7424 - loss: 0.6930\n",
            "Epoch 17: val_accuracy did not improve from 0.84127\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 8s/step - accuracy: 0.7430 - loss: 0.6912 - val_accuracy: 0.7460 - val_loss: 0.6913 - learning_rate: 2.0000e-06\n",
            "Epoch 18/60\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.8089 - loss: 0.4788\n",
            "Epoch 18: val_accuracy did not improve from 0.84127\n",
            "\n",
            "Epoch 18: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 8s/step - accuracy: 0.8069 - loss: 0.4823 - val_accuracy: 0.7619 - val_loss: 0.6686 - learning_rate: 2.0000e-06\n",
            "Epoch 19/60\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.7460 - loss: 0.6266\n",
            "Epoch 19: val_accuracy did not improve from 0.84127\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 8s/step - accuracy: 0.7476 - loss: 0.6218 - val_accuracy: 0.7460 - val_loss: 0.6528 - learning_rate: 1.0000e-06\n",
            "Epoch 20/60\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8s/step - accuracy: 0.8184 - loss: 0.4583\n",
            "Epoch 20: val_accuracy did not improve from 0.84127\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 9s/step - accuracy: 0.8170 - loss: 0.4632 - val_accuracy: 0.7619 - val_loss: 0.7114 - learning_rate: 1.0000e-06\n",
            "Epoch 21/60\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.7854 - loss: 0.4847\n",
            "Epoch 21: val_accuracy did not improve from 0.84127\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 8s/step - accuracy: 0.7857 - loss: 0.4863 - val_accuracy: 0.7619 - val_loss: 0.6404 - learning_rate: 1.0000e-06\n",
            "Epoch 22/60\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.8080 - loss: 0.5468\n",
            "Epoch 22: val_accuracy did not improve from 0.84127\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 8s/step - accuracy: 0.8081 - loss: 0.5445 - val_accuracy: 0.7778 - val_loss: 0.6539 - learning_rate: 1.0000e-06\n",
            "Epoch 23/60\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.7634 - loss: 0.6529\n",
            "Epoch 23: val_accuracy did not improve from 0.84127\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 8s/step - accuracy: 0.7621 - loss: 0.6515 - val_accuracy: 0.7778 - val_loss: 0.7425 - learning_rate: 1.0000e-06\n",
            "Epoch 23: early stopping\n",
            "Restoring model weights from the end of the best epoch: 16.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/saving/saving_lib.py:802: UserWarning: Skipping variable loading for optimizer 'adam', because it has 182 variables whereas the saved optimizer has 18 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training complete.\n",
            "Best restored validation accuracy: 80.95%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import ResNet50V2, DenseNet121\n",
        "from tensorflow.keras.layers import (\n",
        "    Dense, GlobalAveragePooling2D, Dropout, BatchNormalization, Concatenate, Input\n",
        ")\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import (\n",
        "    ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        ")\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Paths & hyperparameters\n",
        "base_dir = \"/content/drive/MyDrive/BTECHPROJ\"\n",
        "img_size = (224, 224)\n",
        "batch_size = 16\n",
        "num_classes = 3\n",
        "epochs = 40\n",
        "\n",
        "# Data Generators\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    validation_split=0.2,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    brightness_range=[0.8, 1.2],\n",
        "    shear_range=0.1,\n",
        "    zoom_range=0.15,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "val_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
        "\n",
        "train_gen = train_datagen.flow_from_directory(\n",
        "    base_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    subset='training',\n",
        "    class_mode='categorical',\n",
        "    shuffle=True,\n",
        "    seed=42\n",
        ")\n",
        "val_gen = val_datagen.flow_from_directory(\n",
        "    base_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    subset='validation',\n",
        "    class_mode='categorical',\n",
        "    shuffle=False,\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "# --- Load your ResNet model base ---\n",
        "resnet_base = ResNet50V2(weights=\"imagenet\", include_top=False, input_shape=img_size + (3,))\n",
        "resnet_base.trainable = False\n",
        "\n",
        "# --- Load DenseNet base ---\n",
        "densenet_base = DenseNet121(weights=\"imagenet\", include_top=False, input_shape=img_size + (3,))\n",
        "densenet_base.trainable = False\n",
        "\n",
        "# Common input\n",
        "inputs = Input(shape=img_size + (3,))\n",
        "\n",
        "# Extract features correctly\n",
        "resnet_features = resnet_base(inputs)\n",
        "densenet_features = densenet_base(inputs)\n",
        "\n",
        "# Feature Fusion (same spatial size: 7x7)\n",
        "merged = Concatenate(axis=-1)([resnet_features, densenet_features])  # 7x7x(3072)\n",
        "\n",
        "x = GlobalAveragePooling2D()(merged)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.4)(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.3)(x)\n",
        "outputs = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "hybrid_model = Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "# Compile\n",
        "hybrid_model.compile(\n",
        "    optimizer=Adam(learning_rate=1e-4),\n",
        "    loss=CategoricalCrossentropy(label_smoothing=0.1),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Callbacks\n",
        "callbacks = [\n",
        "    ModelCheckpoint(\n",
        "        filepath=\"/content/drive/MyDrive/BTECHPROJ/best_hybrid_fixed.keras\",\n",
        "        monitor='val_accuracy',\n",
        "        save_best_only=True,\n",
        "        mode='max',\n",
        "        verbose=1\n",
        "    ),\n",
        "    EarlyStopping(\n",
        "        monitor='val_accuracy',\n",
        "        patience=8,\n",
        "        restore_best_weights=True,\n",
        "        verbose=1\n",
        "    ),\n",
        "    ReduceLROnPlateau(\n",
        "        monitor='val_loss',\n",
        "        factor=0.3,\n",
        "        patience=3,\n",
        "        min_lr=1e-7,\n",
        "        verbose=1\n",
        "    )\n",
        "]\n",
        "\n",
        "# Train the hybrid model\n",
        "print(\"Training properly fused ResNet50V2 + DenseNet121 feature ensemble...\")\n",
        "history = hybrid_model.fit(\n",
        "    train_gen,\n",
        "    validation_data=val_gen,\n",
        "    epochs=epochs,\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Evaluate final model\n",
        "hybrid_model.load_weights(\"/content/drive/MyDrive/BTECHPROJ/best_hybrid_fixed.keras\")\n",
        "val_loss, val_acc = hybrid_model.evaluate(val_gen, verbose=0)\n",
        "print(f\"Hybrid ensemble training complete. Final validation accuracy: {val_acc * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CjHC3MTBxJ49",
        "outputId": "2fff887d-5ec4-4027-fe4b-fd97e002067c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Found 254 images belonging to 3 classes.\n",
            "Found 63 images belonging to 3 classes.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m94668760/94668760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Training properly fused ResNet50V2 + DenseNet121 feature ensemble...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11s/step - accuracy: 0.3961 - loss: 1.6159 \n",
            "Epoch 1: val_accuracy improved from -inf to 0.76190, saving model to /content/drive/MyDrive/BTECHPROJ/best_hybrid_fixed.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 19s/step - accuracy: 0.4029 - loss: 1.6003 - val_accuracy: 0.7619 - val_loss: 0.7321 - learning_rate: 1.0000e-04\n",
            "Epoch 2/40\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.6679 - loss: 0.9578\n",
            "Epoch 2: val_accuracy did not improve from 0.76190\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 7s/step - accuracy: 0.6710 - loss: 0.9541 - val_accuracy: 0.7619 - val_loss: 0.6848 - learning_rate: 1.0000e-04\n",
            "Epoch 3/40\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.7817 - loss: 0.7365\n",
            "Epoch 3: val_accuracy improved from 0.76190 to 0.77778, saving model to /content/drive/MyDrive/BTECHPROJ/best_hybrid_fixed.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 7s/step - accuracy: 0.7804 - loss: 0.7388 - val_accuracy: 0.7778 - val_loss: 0.6631 - learning_rate: 1.0000e-04\n",
            "Epoch 4/40\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.7557 - loss: 0.8369\n",
            "Epoch 4: val_accuracy did not improve from 0.77778\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 8s/step - accuracy: 0.7581 - loss: 0.8325 - val_accuracy: 0.7778 - val_loss: 0.6402 - learning_rate: 1.0000e-04\n",
            "Epoch 5/40\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8120 - loss: 0.8013\n",
            "Epoch 5: val_accuracy improved from 0.77778 to 0.79365, saving model to /content/drive/MyDrive/BTECHPROJ/best_hybrid_fixed.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 7s/step - accuracy: 0.8133 - loss: 0.7966 - val_accuracy: 0.7937 - val_loss: 0.6221 - learning_rate: 1.0000e-04\n",
            "Epoch 6/40\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.7972 - loss: 0.7465\n",
            "Epoch 6: val_accuracy did not improve from 0.79365\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 7s/step - accuracy: 0.7985 - loss: 0.7442 - val_accuracy: 0.7937 - val_loss: 0.5971 - learning_rate: 1.0000e-04\n",
            "Epoch 7/40\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8316 - loss: 0.6215\n",
            "Epoch 7: val_accuracy improved from 0.79365 to 0.80952, saving model to /content/drive/MyDrive/BTECHPROJ/best_hybrid_fixed.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 7s/step - accuracy: 0.8304 - loss: 0.6239 - val_accuracy: 0.8095 - val_loss: 0.6105 - learning_rate: 1.0000e-04\n",
            "Epoch 8/40\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8496 - loss: 0.6616\n",
            "Epoch 8: val_accuracy did not improve from 0.80952\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 7s/step - accuracy: 0.8506 - loss: 0.6597 - val_accuracy: 0.7937 - val_loss: 0.6172 - learning_rate: 1.0000e-04\n",
            "Epoch 9/40\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.8389 - loss: 0.6496\n",
            "Epoch 9: val_accuracy did not improve from 0.80952\n",
            "\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 2.9999999242136255e-05.\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 8s/step - accuracy: 0.8384 - loss: 0.6505 - val_accuracy: 0.8095 - val_loss: 0.6048 - learning_rate: 1.0000e-04\n",
            "Epoch 10/40\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.8901 - loss: 0.6020\n",
            "Epoch 10: val_accuracy improved from 0.80952 to 0.82540, saving model to /content/drive/MyDrive/BTECHPROJ/best_hybrid_fixed.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 8s/step - accuracy: 0.8905 - loss: 0.6009 - val_accuracy: 0.8254 - val_loss: 0.6005 - learning_rate: 3.0000e-05\n",
            "Epoch 11/40\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8594 - loss: 0.6088\n",
            "Epoch 11: val_accuracy did not improve from 0.82540\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 7s/step - accuracy: 0.8600 - loss: 0.6090 - val_accuracy: 0.8254 - val_loss: 0.6088 - learning_rate: 3.0000e-05\n",
            "Epoch 12/40\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8797 - loss: 0.5920\n",
            "Epoch 12: val_accuracy did not improve from 0.82540\n",
            "\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 8.999999772640877e-06.\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 7s/step - accuracy: 0.8814 - loss: 0.5891 - val_accuracy: 0.8095 - val_loss: 0.6213 - learning_rate: 3.0000e-05\n",
            "Epoch 13/40\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9263 - loss: 0.5077\n",
            "Epoch 13: val_accuracy did not improve from 0.82540\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 7s/step - accuracy: 0.9246 - loss: 0.5093 - val_accuracy: 0.8095 - val_loss: 0.6326 - learning_rate: 9.0000e-06\n",
            "Epoch 14/40\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.9054 - loss: 0.5923\n",
            "Epoch 14: val_accuracy did not improve from 0.82540\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 7s/step - accuracy: 0.9047 - loss: 0.5927 - val_accuracy: 0.8095 - val_loss: 0.6400 - learning_rate: 9.0000e-06\n",
            "Epoch 15/40\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9112 - loss: 0.5725\n",
            "Epoch 15: val_accuracy did not improve from 0.82540\n",
            "\n",
            "Epoch 15: ReduceLROnPlateau reducing learning rate to 2.6999998226528985e-06.\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 7s/step - accuracy: 0.9100 - loss: 0.5734 - val_accuracy: 0.8095 - val_loss: 0.6470 - learning_rate: 9.0000e-06\n",
            "Epoch 16/40\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.8509 - loss: 0.6335\n",
            "Epoch 16: val_accuracy did not improve from 0.82540\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 7s/step - accuracy: 0.8509 - loss: 0.6331 - val_accuracy: 0.8095 - val_loss: 0.6531 - learning_rate: 2.7000e-06\n",
            "Epoch 17/40\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8227 - loss: 0.7309\n",
            "Epoch 17: val_accuracy did not improve from 0.82540\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 7s/step - accuracy: 0.8252 - loss: 0.7249 - val_accuracy: 0.8095 - val_loss: 0.6661 - learning_rate: 2.7000e-06\n",
            "Epoch 18/40\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9034 - loss: 0.5397\n",
            "Epoch 18: val_accuracy did not improve from 0.82540\n",
            "\n",
            "Epoch 18: ReduceLROnPlateau reducing learning rate to 8.099999604382901e-07.\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 7s/step - accuracy: 0.9019 - loss: 0.5429 - val_accuracy: 0.8095 - val_loss: 0.6770 - learning_rate: 2.7000e-06\n",
            "Epoch 18: early stopping\n",
            "Restoring model weights from the end of the best epoch: 10.\n",
            "Hybrid ensemble training complete. Final validation accuracy: 82.54%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import ResNet50V2, DenseNet121, MobileNetV2\n",
        "from tensorflow.keras.layers import (\n",
        "    Dense, GlobalAveragePooling2D, Dropout, BatchNormalization,\n",
        "    Concatenate, Input, Multiply, Add\n",
        ")\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import (\n",
        "    ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        ")\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# ====================\n",
        "# Paths & Hyperparams\n",
        "# ====================\n",
        "base_dir = \"/content/drive/MyDrive/BTECHPROJ\"\n",
        "img_size = (224, 224)\n",
        "batch_size = 16\n",
        "num_classes = 3\n",
        "epochs = 50\n",
        "initial_lr = 1e-4\n",
        "\n",
        "# ================\n",
        "# Data Generators\n",
        "# ================\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    validation_split=0.2,\n",
        "    rotation_range=25,\n",
        "    width_shift_range=0.15,\n",
        "    height_shift_range=0.15,\n",
        "    brightness_range=[0.8, 1.2],\n",
        "    shear_range=0.15,\n",
        "    zoom_range=0.15,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='reflect'\n",
        ")\n",
        "val_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
        "\n",
        "train_gen = train_datagen.flow_from_directory(\n",
        "    base_dir, target_size=img_size, batch_size=batch_size,\n",
        "    subset='training', class_mode='categorical', shuffle=True, seed=42\n",
        ")\n",
        "val_gen = val_datagen.flow_from_directory(\n",
        "    base_dir, target_size=img_size, batch_size=batch_size,\n",
        "    subset='validation', class_mode='categorical', shuffle=False, seed=42\n",
        ")\n",
        "\n",
        "# ================\n",
        "#  Backbone Models\n",
        "# ================\n",
        "resnet = ResNet50V2(weights=\"imagenet\", include_top=False, input_shape=img_size + (3,))\n",
        "densenet = DenseNet121(weights=\"imagenet\", include_top=False, input_shape=img_size + (3,))\n",
        "mobilenet = MobileNetV2(weights=\"imagenet\", include_top=False, input_shape=img_size + (3,))\n",
        "\n",
        "resnet.trainable = False\n",
        "densenet.trainable = False\n",
        "mobilenet.trainable = False\n",
        "\n",
        "# ==========================\n",
        "# Attention‑weighted Fusion\n",
        "# ==========================\n",
        "inputs = Input(shape=img_size + (3,))\n",
        "\n",
        "r_feat = resnet(inputs)\n",
        "d_feat = densenet(inputs)\n",
        "m_feat = mobilenet(inputs)\n",
        "\n",
        "# All outputs are roughly (7×7×n); concatenate feature maps\n",
        "merged = Concatenate(axis=-1)([r_feat, d_feat, m_feat])\n",
        "\n",
        "from tensorflow.keras.layers import Reshape, Multiply\n",
        "\n",
        "gap = GlobalAveragePooling2D()(merged)\n",
        "gate = Dense(merged.shape[-1], activation=\"sigmoid\")(gap)\n",
        "gate_reshaped = Reshape((1, 1, merged.shape[-1]))(gate)\n",
        "weighted_features = Multiply()([merged, gate_reshaped])  # apply attention\n",
        "\n",
        "# =====================\n",
        "#  Classification Head\n",
        "# =====================\n",
        "x = GlobalAveragePooling2D()(weighted_features)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.4)(x)\n",
        "x = Dense(512, activation='relu', kernel_regularizer=l2(0.001))(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.3)(x)\n",
        "outputs = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "# ===================\n",
        "#  Compile & Metrics\n",
        "# ===================\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=initial_lr),\n",
        "    loss=CategoricalCrossentropy(label_smoothing=0.1),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# ===============\n",
        "#  Callback setup\n",
        "# ===============\n",
        "callbacks = [\n",
        "    ModelCheckpoint(\n",
        "        filepath=\"/content/drive/MyDrive/BTECHPROJ/best_tri_hybrid.keras\",\n",
        "        monitor='val_accuracy', save_best_only=True,\n",
        "        mode='max', verbose=1\n",
        "    ),\n",
        "    EarlyStopping(\n",
        "        monitor='val_accuracy', patience=8,\n",
        "        restore_best_weights=True, verbose=1\n",
        "    ),\n",
        "    ReduceLROnPlateau(\n",
        "        monitor='val_loss', factor=0.3,\n",
        "        patience=3, min_lr=1e-7, verbose=1\n",
        "    )\n",
        "]\n",
        "\n",
        "# ==================\n",
        "#  Train the model\n",
        "# ==================\n",
        "print(\"Training triple hybrid model (ResNet + DenseNet + MobileNet with attention fusion)...\")\n",
        "history = model.fit(\n",
        "    train_gen,\n",
        "    validation_data=val_gen,\n",
        "    epochs=epochs,\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# =======================\n",
        "#  Evaluation & Results\n",
        "# =======================\n",
        "model.load_weights(\"/content/drive/MyDrive/BTECHPROJ/best_tri_hybrid.keras\")\n",
        "val_loss, val_acc = model.evaluate(val_gen, verbose=0)\n",
        "print(f\"Triple‑hybrid model complete. Final validation accuracy: {val_acc * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-iMI3v1o37Nr",
        "outputId": "e3a65847-2020-4f79-aa56-5f963c25b3c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Found 254 images belonging to 3 classes.\n",
            "Found 63 images belonging to 3 classes.\n",
            "Training triple hybrid model (ResNet + DenseNet + MobileNet with attention fusion)...\n",
            "Epoch 1/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.4905 - loss: 2.2656\n",
            "Epoch 1: val_accuracy improved from -inf to 0.58730, saving model to /content/drive/MyDrive/BTECHPROJ/best_tri_hybrid.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 9s/step - accuracy: 0.5006 - loss: 2.2473 - val_accuracy: 0.5873 - val_loss: 1.7272 - learning_rate: 1.0000e-04\n",
            "Epoch 2/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.8843 - loss: 1.5111\n",
            "Epoch 2: val_accuracy improved from 0.58730 to 0.71429, saving model to /content/drive/MyDrive/BTECHPROJ/best_tri_hybrid.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 10s/step - accuracy: 0.8846 - loss: 1.5111 - val_accuracy: 0.7143 - val_loss: 1.6400 - learning_rate: 1.0000e-04\n",
            "Epoch 3/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9091 - loss: 1.4606\n",
            "Epoch 3: val_accuracy did not improve from 0.71429\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 9s/step - accuracy: 0.9079 - loss: 1.4606 - val_accuracy: 0.7143 - val_loss: 1.6513 - learning_rate: 1.0000e-04\n",
            "Epoch 4/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9012 - loss: 1.3947\n",
            "Epoch 4: val_accuracy improved from 0.71429 to 0.73016, saving model to /content/drive/MyDrive/BTECHPROJ/best_tri_hybrid.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 9s/step - accuracy: 0.8998 - loss: 1.3956 - val_accuracy: 0.7302 - val_loss: 1.6310 - learning_rate: 1.0000e-04\n",
            "Epoch 5/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.8756 - loss: 1.4476\n",
            "Epoch 5: val_accuracy improved from 0.73016 to 0.77778, saving model to /content/drive/MyDrive/BTECHPROJ/best_tri_hybrid.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 9s/step - accuracy: 0.8771 - loss: 1.4468 - val_accuracy: 0.7778 - val_loss: 1.5512 - learning_rate: 1.0000e-04\n",
            "Epoch 6/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9087 - loss: 1.3982\n",
            "Epoch 6: val_accuracy did not improve from 0.77778\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 10s/step - accuracy: 0.9078 - loss: 1.4006 - val_accuracy: 0.7619 - val_loss: 1.5314 - learning_rate: 1.0000e-04\n",
            "Epoch 7/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.8860 - loss: 1.3912\n",
            "Epoch 7: val_accuracy did not improve from 0.77778\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 9s/step - accuracy: 0.8870 - loss: 1.3904 - val_accuracy: 0.7619 - val_loss: 1.5259 - learning_rate: 1.0000e-04\n",
            "Epoch 8/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.8921 - loss: 1.4209\n",
            "Epoch 8: val_accuracy did not improve from 0.77778\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 8s/step - accuracy: 0.8928 - loss: 1.4188 - val_accuracy: 0.7778 - val_loss: 1.4512 - learning_rate: 1.0000e-04\n",
            "Epoch 9/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.9471 - loss: 1.3284\n",
            "Epoch 9: val_accuracy did not improve from 0.77778\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 8s/step - accuracy: 0.9456 - loss: 1.3310 - val_accuracy: 0.7778 - val_loss: 1.4572 - learning_rate: 1.0000e-04\n",
            "Epoch 10/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9458 - loss: 1.2973\n",
            "Epoch 10: val_accuracy did not improve from 0.77778\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 8s/step - accuracy: 0.9462 - loss: 1.2974 - val_accuracy: 0.7619 - val_loss: 1.4180 - learning_rate: 1.0000e-04\n",
            "Epoch 11/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8776 - loss: 1.3600\n",
            "Epoch 11: val_accuracy did not improve from 0.77778\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 9s/step - accuracy: 0.8797 - loss: 1.3583 - val_accuracy: 0.7778 - val_loss: 1.3852 - learning_rate: 1.0000e-04\n",
            "Epoch 12/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9358 - loss: 1.3029\n",
            "Epoch 12: val_accuracy improved from 0.77778 to 0.79365, saving model to /content/drive/MyDrive/BTECHPROJ/best_tri_hybrid.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 9s/step - accuracy: 0.9363 - loss: 1.3019 - val_accuracy: 0.7937 - val_loss: 1.3881 - learning_rate: 1.0000e-04\n",
            "Epoch 13/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9653 - loss: 1.2768\n",
            "Epoch 13: val_accuracy did not improve from 0.79365\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 9s/step - accuracy: 0.9652 - loss: 1.2762 - val_accuracy: 0.7937 - val_loss: 1.4191 - learning_rate: 1.0000e-04\n",
            "Epoch 14/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9354 - loss: 1.2537\n",
            "Epoch 14: val_accuracy improved from 0.79365 to 0.82540, saving model to /content/drive/MyDrive/BTECHPROJ/best_tri_hybrid.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 9s/step - accuracy: 0.9358 - loss: 1.2534 - val_accuracy: 0.8254 - val_loss: 1.3755 - learning_rate: 1.0000e-04\n",
            "Epoch 15/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9189 - loss: 1.3133\n",
            "Epoch 15: val_accuracy did not improve from 0.82540\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 9s/step - accuracy: 0.9202 - loss: 1.3111 - val_accuracy: 0.8095 - val_loss: 1.3630 - learning_rate: 1.0000e-04\n",
            "Epoch 16/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9456 - loss: 1.2698\n",
            "Epoch 16: val_accuracy did not improve from 0.82540\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 8s/step - accuracy: 0.9458 - loss: 1.2700 - val_accuracy: 0.7937 - val_loss: 1.3957 - learning_rate: 1.0000e-04\n",
            "Epoch 17/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9294 - loss: 1.2505\n",
            "Epoch 17: val_accuracy did not improve from 0.82540\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 8s/step - accuracy: 0.9292 - loss: 1.2510 - val_accuracy: 0.7937 - val_loss: 1.4572 - learning_rate: 1.0000e-04\n",
            "Epoch 18/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9407 - loss: 1.2167\n",
            "Epoch 18: val_accuracy did not improve from 0.82540\n",
            "\n",
            "Epoch 18: ReduceLROnPlateau reducing learning rate to 2.9999999242136255e-05.\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 9s/step - accuracy: 0.9416 - loss: 1.2161 - val_accuracy: 0.7937 - val_loss: 1.3978 - learning_rate: 1.0000e-04\n",
            "Epoch 19/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.9834 - loss: 1.1998\n",
            "Epoch 19: val_accuracy did not improve from 0.82540\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 8s/step - accuracy: 0.9832 - loss: 1.2000 - val_accuracy: 0.7937 - val_loss: 1.3843 - learning_rate: 3.0000e-05\n",
            "Epoch 20/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.9566 - loss: 1.2131\n",
            "Epoch 20: val_accuracy did not improve from 0.82540\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 8s/step - accuracy: 0.9573 - loss: 1.2130 - val_accuracy: 0.8095 - val_loss: 1.3649 - learning_rate: 3.0000e-05\n",
            "Epoch 21/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9584 - loss: 1.2240\n",
            "Epoch 21: val_accuracy did not improve from 0.82540\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 8s/step - accuracy: 0.9588 - loss: 1.2237 - val_accuracy: 0.8095 - val_loss: 1.3615 - learning_rate: 3.0000e-05\n",
            "Epoch 22/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.9176 - loss: 1.2364\n",
            "Epoch 22: val_accuracy did not improve from 0.82540\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 9s/step - accuracy: 0.9192 - loss: 1.2362 - val_accuracy: 0.8095 - val_loss: 1.3946 - learning_rate: 3.0000e-05\n",
            "Epoch 22: early stopping\n",
            "Restoring model weights from the end of the best epoch: 14.\n",
            "Triple‑hybrid model complete. Final validation accuracy: 82.54%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#iske neechey wala hai main code."
      ],
      "metadata": {
        "id": "wRTIYXeRyvou"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import ResNet50V2, DenseNet121, MobileNetV2\n",
        "from tensorflow.keras.layers import (\n",
        "    Dense, GlobalAveragePooling2D, Dropout, BatchNormalization,\n",
        "    Concatenate, Input, Multiply, Reshape\n",
        ")\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import (\n",
        "    ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, LearningRateScheduler\n",
        ")\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Parameters\n",
        "base_dir = \"/content/drive/MyDrive/BTECHPROJ\"\n",
        "img_size = (224, 224)\n",
        "batch_size = 16\n",
        "num_classes = 3\n",
        "epochs_initial = 40\n",
        "epochs_finetune = 30\n",
        "initial_lr = 1e-4\n",
        "\n",
        "# Data Augmentation and Validation Generators\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    validation_split=0.2,\n",
        "    rotation_range=25,\n",
        "    width_shift_range=0.15,\n",
        "    height_shift_range=0.15,\n",
        "    brightness_range=[0.8, 1.2],\n",
        "    shear_range=0.15,\n",
        "    zoom_range=0.15,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='reflect'\n",
        ")\n",
        "val_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
        "\n",
        "train_gen = train_datagen.flow_from_directory(\n",
        "    base_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    subset='training',\n",
        "    class_mode='categorical',\n",
        "    shuffle=True,\n",
        "    seed=42\n",
        ")\n",
        "val_gen = val_datagen.flow_from_directory(\n",
        "    base_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    subset='validation',\n",
        "    class_mode='categorical',\n",
        "    shuffle=False,\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "# Load backbone models\n",
        "resnet = ResNet50V2(weights=\"imagenet\", include_top=False, input_shape=img_size + (3,))\n",
        "densenet = DenseNet121(weights=\"imagenet\", include_top=False, input_shape=img_size + (3,))\n",
        "mobilenet = MobileNetV2(weights=\"imagenet\", include_top=False, input_shape=img_size + (3,))\n",
        "\n",
        "# Freeze backbones initially\n",
        "resnet.trainable = False\n",
        "densenet.trainable = False\n",
        "mobilenet.trainable = False\n",
        "\n",
        "# Input and extract features\n",
        "inputs = Input(shape=img_size + (3,))\n",
        "r_feat = resnet(inputs)\n",
        "d_feat = densenet(inputs)\n",
        "m_feat = mobilenet(inputs)\n",
        "\n",
        "merged = Concatenate(axis=-1)([r_feat, d_feat, m_feat])\n",
        "\n",
        "gap = GlobalAveragePooling2D()(merged)\n",
        "gate = Dense(merged.shape[-1], activation=\"sigmoid\")(gap)\n",
        "gate_reshaped = Reshape((1, 1, merged.shape[-1]))(gate)\n",
        "weighted_features = Multiply()([merged, gate_reshaped])\n",
        "\n",
        "# Classification head\n",
        "x = GlobalAveragePooling2D()(weighted_features)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.4)(x)\n",
        "x = Dense(512, activation='relu', kernel_regularizer=l2(0.001))(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.3)(x)\n",
        "outputs = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "# Compile model\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=initial_lr),\n",
        "    loss=CategoricalCrossentropy(label_smoothing=0.1),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Callbacks including cosine annealing LR scheduler\n",
        "def cosine_annealing_scheduler(epoch, lr):\n",
        "    max_lr = initial_lr\n",
        "    min_lr = 1e-7\n",
        "    decay = 0.5 * (1 + math.cos(math.pi * epoch / epochs_finetune))\n",
        "    new_lr = min_lr + (max_lr - min_lr) * decay\n",
        "    print(f\"Epoch {epoch+1}: setting learning rate to {new_lr}\")\n",
        "    return new_lr\n",
        "\n",
        "callbacks = [\n",
        "    ModelCheckpoint(\n",
        "        filepath=\"/content/drive/MyDrive/BTECHPROJ/best_tri_hybrid_cosine.keras\",\n",
        "        monitor='val_accuracy',\n",
        "        save_best_only=True,\n",
        "        mode='max',\n",
        "        verbose=1\n",
        "    ),\n",
        "    EarlyStopping(\n",
        "        monitor='val_accuracy',\n",
        "        patience=10,\n",
        "        restore_best_weights=True,\n",
        "        verbose=1\n",
        "    ),\n",
        "    ReduceLROnPlateau(\n",
        "        monitor='val_loss',\n",
        "        factor=0.3,\n",
        "        patience=3,\n",
        "        min_lr=1e-7,\n",
        "        verbose=1\n",
        "    ),\n",
        "    LearningRateScheduler(cosine_annealing_scheduler, verbose=1)\n",
        "]\n",
        "\n",
        "# Train frozen backbones first\n",
        "history = model.fit(\n",
        "    train_gen,\n",
        "    validation_data=val_gen,\n",
        "    epochs=epochs_initial,\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Unfreeze last layers progressively for fine-tuning\n",
        "backbones = [resnet, densenet, mobilenet]\n",
        "for backbone in backbones:\n",
        "    # Freeze all layers except the last 30\n",
        "    for layer in backbone.layers[:-30]:\n",
        "        layer.trainable = False\n",
        "    for layer in backbone.layers[-30:]:\n",
        "        layer.trainable = True\n",
        "\n",
        "# Compile fine-tuning model with low LR\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=1e-5),\n",
        "    loss=CategoricalCrossentropy(label_smoothing=0.1),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Fine-tune\n",
        "history_fine = model.fit(\n",
        "    train_gen,\n",
        "    validation_data=val_gen,\n",
        "    epochs=epochs_initial + epochs_finetune,\n",
        "    initial_epoch=history.epoch[-1],\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Load best weights and evaluate\n",
        "model.load_weights(\"/content/drive/MyDrive/BTECHPROJ/best_tri_hybrid_cosine.keras\")\n",
        "val_loss, val_acc = model.evaluate(val_gen, verbose=0)\n",
        "print(f\"Tri-model hybrid with cosine LR training complete. Validation accuracy: {val_acc*100:.2f}%\")\n"
      ],
      "metadata": {
        "id": "3uX2M9-jXYDg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6861ef2c-99ed-405d-a9d3-433b4e47529e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Found 254 images belonging to 3 classes.\n",
            "Found 63 images belonging to 3 classes.\n",
            "Epoch 1: setting learning rate to 0.0001\n",
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 1/40\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.4523 - loss: 2.3520\n",
            "Epoch 1: val_accuracy improved from -inf to 0.53968, saving model to /content/drive/MyDrive/BTECHPROJ/best_tri_hybrid_cosine.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 9s/step - accuracy: 0.4620 - loss: 2.3303 - val_accuracy: 0.5397 - val_loss: 1.8141 - learning_rate: 1.0000e-04\n",
            "Epoch 2: setting learning rate to 9.972636867364526e-05\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 9.972636867364526e-05.\n",
            "Epoch 2/40\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.8122 - loss: 1.6007\n",
            "Epoch 2: val_accuracy improved from 0.53968 to 0.69841, saving model to /content/drive/MyDrive/BTECHPROJ/best_tri_hybrid_cosine.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 9s/step - accuracy: 0.8147 - loss: 1.5974 - val_accuracy: 0.6984 - val_loss: 1.7212 - learning_rate: 9.9726e-05\n",
            "Epoch 3: setting learning rate to 9.89084726566536e-05\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 9.89084726566536e-05.\n",
            "Epoch 3/40\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.8771 - loss: 1.4684\n",
            "Epoch 3: val_accuracy improved from 0.69841 to 0.73016, saving model to /content/drive/MyDrive/BTECHPROJ/best_tri_hybrid_cosine.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 9s/step - accuracy: 0.8765 - loss: 1.4694 - val_accuracy: 0.7302 - val_loss: 1.6964 - learning_rate: 9.8908e-05\n",
            "Epoch 4: setting learning rate to 9.755527298894293e-05\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 9.755527298894293e-05.\n",
            "Epoch 4/40\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9193 - loss: 1.4254\n",
            "Epoch 4: val_accuracy improved from 0.73016 to 0.79365, saving model to /content/drive/MyDrive/BTECHPROJ/best_tri_hybrid_cosine.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 9s/step - accuracy: 0.9178 - loss: 1.4278 - val_accuracy: 0.7937 - val_loss: 1.6701 - learning_rate: 9.7555e-05\n",
            "Epoch 5: setting learning rate to 9.568159560924791e-05\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 9.568159560924791e-05.\n",
            "Epoch 5/40\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.8525 - loss: 1.4881\n",
            "Epoch 5: val_accuracy improved from 0.79365 to 0.80952, saving model to /content/drive/MyDrive/BTECHPROJ/best_tri_hybrid_cosine.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 9s/step - accuracy: 0.8549 - loss: 1.4836 - val_accuracy: 0.8095 - val_loss: 1.6395 - learning_rate: 9.5682e-05\n",
            "Epoch 6: setting learning rate to 9.330796891903273e-05\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 9.330796891903273e-05.\n",
            "Epoch 6/40\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.8827 - loss: 1.4470\n",
            "Epoch 6: val_accuracy did not improve from 0.80952\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 9s/step - accuracy: 0.8839 - loss: 1.4455 - val_accuracy: 0.7619 - val_loss: 1.5878 - learning_rate: 9.3308e-05\n",
            "Epoch 7: setting learning rate to 9.046039886902862e-05\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 9.046039886902862e-05.\n",
            "Epoch 7/40\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9338 - loss: 1.3413\n",
            "Epoch 7: val_accuracy did not improve from 0.80952\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 8s/step - accuracy: 0.9337 - loss: 1.3410 - val_accuracy: 0.7619 - val_loss: 1.5953 - learning_rate: 9.0460e-05\n",
            "Epoch 8: setting learning rate to 8.717008403259584e-05\n",
            "\n",
            "Epoch 8: LearningRateScheduler setting learning rate to 8.717008403259584e-05.\n",
            "Epoch 8/40\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9011 - loss: 1.4030\n",
            "Epoch 8: val_accuracy improved from 0.80952 to 0.85714, saving model to /content/drive/MyDrive/BTECHPROJ/best_tri_hybrid_cosine.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 8s/step - accuracy: 0.9011 - loss: 1.4015 - val_accuracy: 0.8571 - val_loss: 1.5143 - learning_rate: 8.7170e-05\n",
            "Epoch 9: setting learning rate to 8.347307378762497e-05\n",
            "\n",
            "Epoch 9: LearningRateScheduler setting learning rate to 8.347307378762497e-05.\n",
            "Epoch 9/40\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9107 - loss: 1.3320\n",
            "Epoch 9: val_accuracy did not improve from 0.85714\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 9s/step - accuracy: 0.9113 - loss: 1.3321 - val_accuracy: 0.8413 - val_loss: 1.5025 - learning_rate: 8.3473e-05\n",
            "Epoch 10: setting learning rate to 7.940987335200904e-05\n",
            "\n",
            "Epoch 10: LearningRateScheduler setting learning rate to 7.940987335200904e-05.\n",
            "Epoch 10/40\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.9286 - loss: 1.3352\n",
            "Epoch 10: val_accuracy did not improve from 0.85714\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 9s/step - accuracy: 0.9275 - loss: 1.3374 - val_accuracy: 0.8413 - val_loss: 1.4855 - learning_rate: 7.9410e-05\n",
            "Epoch 11: setting learning rate to 7.502500000000001e-05\n",
            "\n",
            "Epoch 11: LearningRateScheduler setting learning rate to 7.502500000000001e-05.\n",
            "Epoch 11/40\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.8990 - loss: 1.3052\n",
            "Epoch 11: val_accuracy did not improve from 0.85714\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 8s/step - accuracy: 0.9003 - loss: 1.3050 - val_accuracy: 0.8254 - val_loss: 1.4551 - learning_rate: 7.5025e-05\n",
            "Epoch 12: setting learning rate to 7.036649532163623e-05\n",
            "\n",
            "Epoch 12: LearningRateScheduler setting learning rate to 7.036649532163623e-05.\n",
            "Epoch 12/40\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.9370 - loss: 1.2974\n",
            "Epoch 12: val_accuracy improved from 0.85714 to 0.88889, saving model to /content/drive/MyDrive/BTECHPROJ/best_tri_hybrid_cosine.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 8s/step - accuracy: 0.9360 - loss: 1.2981 - val_accuracy: 0.8889 - val_loss: 1.4224 - learning_rate: 7.0366e-05\n",
            "Epoch 13: setting learning rate to 6.548539886902863e-05\n",
            "\n",
            "Epoch 13: LearningRateScheduler setting learning rate to 6.548539886902863e-05.\n",
            "Epoch 13/40\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9592 - loss: 1.3090\n",
            "Epoch 13: val_accuracy did not improve from 0.88889\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 9s/step - accuracy: 0.9598 - loss: 1.3071 - val_accuracy: 0.8254 - val_loss: 1.4550 - learning_rate: 6.5485e-05\n",
            "Epoch 14: setting learning rate to 6.0435188956347076e-05\n",
            "\n",
            "Epoch 14: LearningRateScheduler setting learning rate to 6.0435188956347076e-05.\n",
            "Epoch 14/40\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9537 - loss: 1.2509\n",
            "Epoch 14: val_accuracy did not improve from 0.88889\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 8s/step - accuracy: 0.9523 - loss: 1.2525 - val_accuracy: 0.8889 - val_loss: 1.4322 - learning_rate: 6.0435e-05\n",
            "Epoch 15: setting learning rate to 5.52711967402193e-05\n",
            "\n",
            "Epoch 15: LearningRateScheduler setting learning rate to 5.52711967402193e-05.\n",
            "Epoch 15/40\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9530 - loss: 1.2584\n",
            "Epoch 15: val_accuracy did not improve from 0.88889\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 8s/step - accuracy: 0.9539 - loss: 1.2568 - val_accuracy: 0.8889 - val_loss: 1.3949 - learning_rate: 5.5271e-05\n",
            "Epoch 16: setting learning rate to 5.005000000000002e-05\n",
            "\n",
            "Epoch 16: LearningRateScheduler setting learning rate to 5.005000000000002e-05.\n",
            "Epoch 16/40\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.9526 - loss: 1.2390\n",
            "Epoch 16: val_accuracy did not improve from 0.88889\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 8s/step - accuracy: 0.9524 - loss: 1.2392 - val_accuracy: 0.8730 - val_loss: 1.3591 - learning_rate: 5.0050e-05\n",
            "Epoch 17: setting learning rate to 4.4828803259780724e-05\n",
            "\n",
            "Epoch 17: LearningRateScheduler setting learning rate to 4.4828803259780724e-05.\n",
            "Epoch 17/40\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.9623 - loss: 1.2438\n",
            "Epoch 17: val_accuracy did not improve from 0.88889\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 8s/step - accuracy: 0.9627 - loss: 1.2428 - val_accuracy: 0.8730 - val_loss: 1.3530 - learning_rate: 4.4829e-05\n",
            "Epoch 18: setting learning rate to 3.9664811043652924e-05\n",
            "\n",
            "Epoch 18: LearningRateScheduler setting learning rate to 3.9664811043652924e-05.\n",
            "Epoch 18/40\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.9224 - loss: 1.2713\n",
            "Epoch 18: val_accuracy did not improve from 0.88889\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 8s/step - accuracy: 0.9239 - loss: 1.2693 - val_accuracy: 0.8730 - val_loss: 1.3442 - learning_rate: 3.9665e-05\n",
            "Epoch 19: setting learning rate to 3.461460113097139e-05\n",
            "\n",
            "Epoch 19: LearningRateScheduler setting learning rate to 3.461460113097139e-05.\n",
            "Epoch 19/40\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.9715 - loss: 1.2182\n",
            "Epoch 19: val_accuracy did not improve from 0.88889\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 8s/step - accuracy: 0.9702 - loss: 1.2196 - val_accuracy: 0.8889 - val_loss: 1.3214 - learning_rate: 3.4615e-05\n",
            "Epoch 20: setting learning rate to 2.9733504678363788e-05\n",
            "\n",
            "Epoch 20: LearningRateScheduler setting learning rate to 2.9733504678363788e-05.\n",
            "Epoch 20/40\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9536 - loss: 1.2118\n",
            "Epoch 20: val_accuracy did not improve from 0.88889\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 8s/step - accuracy: 0.9519 - loss: 1.2146 - val_accuracy: 0.8889 - val_loss: 1.3054 - learning_rate: 2.9734e-05\n",
            "Epoch 21: setting learning rate to 2.507500000000001e-05\n",
            "\n",
            "Epoch 21: LearningRateScheduler setting learning rate to 2.507500000000001e-05.\n",
            "Epoch 21/40\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.9480 - loss: 1.2374\n",
            "Epoch 21: val_accuracy did not improve from 0.88889\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 9s/step - accuracy: 0.9478 - loss: 1.2386 - val_accuracy: 0.8889 - val_loss: 1.3125 - learning_rate: 2.5075e-05\n",
            "Epoch 22: setting learning rate to 2.069012664799097e-05\n",
            "\n",
            "Epoch 22: LearningRateScheduler setting learning rate to 2.069012664799097e-05.\n",
            "Epoch 22/40\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.9626 - loss: 1.2172\n",
            "Epoch 22: val_accuracy did not improve from 0.88889\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 8s/step - accuracy: 0.9625 - loss: 1.2175 - val_accuracy: 0.8730 - val_loss: 1.3227 - learning_rate: 2.0690e-05\n",
            "Epoch 22: early stopping\n",
            "Restoring model weights from the end of the best epoch: 12.\n",
            "Epoch 22: setting learning rate to 2.069012664799097e-05\n",
            "\n",
            "Epoch 22: LearningRateScheduler setting learning rate to 2.069012664799097e-05.\n",
            "Epoch 22/70\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8s/step - accuracy: 0.8035 - loss: 1.4433\n",
            "Epoch 22: val_accuracy improved from 0.88889 to 0.92063, saving model to /content/drive/MyDrive/BTECHPROJ/best_tri_hybrid_cosine.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 11s/step - accuracy: 0.8049 - loss: 1.4452 - val_accuracy: 0.9206 - val_loss: 1.3863 - learning_rate: 2.0690e-05\n",
            "Epoch 23: setting learning rate to 1.6626926212375046e-05\n",
            "\n",
            "Epoch 23: LearningRateScheduler setting learning rate to 1.6626926212375046e-05.\n",
            "Epoch 23/70\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9s/step - accuracy: 0.8786 - loss: 1.3574\n",
            "Epoch 23: val_accuracy did not improve from 0.92063\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 12s/step - accuracy: 0.8799 - loss: 1.3561 - val_accuracy: 0.9206 - val_loss: 1.3612 - learning_rate: 1.6627e-05\n",
            "Epoch 24: setting learning rate to 1.292991596740417e-05\n",
            "\n",
            "Epoch 24: LearningRateScheduler setting learning rate to 1.292991596740417e-05.\n",
            "Epoch 24/70\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8s/step - accuracy: 0.8643 - loss: 1.3811\n",
            "Epoch 24: val_accuracy did not improve from 0.92063\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 11s/step - accuracy: 0.8635 - loss: 1.3839 - val_accuracy: 0.9206 - val_loss: 1.3475 - learning_rate: 1.2930e-05\n",
            "Epoch 25: setting learning rate to 9.639601130971381e-06\n",
            "\n",
            "Epoch 25: LearningRateScheduler setting learning rate to 9.639601130971381e-06.\n",
            "Epoch 25/70\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8s/step - accuracy: 0.9100 - loss: 1.3434\n",
            "Epoch 25: val_accuracy improved from 0.92063 to 0.93651, saving model to /content/drive/MyDrive/BTECHPROJ/best_tri_hybrid_cosine.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 11s/step - accuracy: 0.9111 - loss: 1.3427 - val_accuracy: 0.9365 - val_loss: 1.3279 - learning_rate: 9.6396e-06\n",
            "Epoch 26: setting learning rate to 6.792031080967287e-06\n",
            "\n",
            "Epoch 26: LearningRateScheduler setting learning rate to 6.792031080967287e-06.\n",
            "Epoch 26/70\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - accuracy: 0.8704 - loss: 1.4018\n",
            "Epoch 26: val_accuracy improved from 0.93651 to 0.95238, saving model to /content/drive/MyDrive/BTECHPROJ/best_tri_hybrid_cosine.keras\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 12s/step - accuracy: 0.8730 - loss: 1.3982 - val_accuracy: 0.9524 - val_loss: 1.3197 - learning_rate: 6.7920e-06\n",
            "Epoch 27: setting learning rate to 4.418404390752081e-06\n",
            "\n",
            "Epoch 27: LearningRateScheduler setting learning rate to 4.418404390752081e-06.\n",
            "Epoch 27/70\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9s/step - accuracy: 0.8864 - loss: 1.3292\n",
            "Epoch 27: val_accuracy did not improve from 0.95238\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 11s/step - accuracy: 0.8868 - loss: 1.3296 - val_accuracy: 0.9206 - val_loss: 1.3237 - learning_rate: 4.4184e-06\n",
            "Epoch 28: setting learning rate to 2.544727011057081e-06\n",
            "\n",
            "Epoch 28: LearningRateScheduler setting learning rate to 2.544727011057081e-06.\n",
            "Epoch 28/70\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8s/step - accuracy: 0.8253 - loss: 1.5036\n",
            "Epoch 28: val_accuracy did not improve from 0.95238\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 10s/step - accuracy: 0.8265 - loss: 1.4989 - val_accuracy: 0.9048 - val_loss: 1.3353 - learning_rate: 2.5447e-06\n",
            "Epoch 29: setting learning rate to 1.1915273433464057e-06\n",
            "\n",
            "Epoch 29: LearningRateScheduler setting learning rate to 1.1915273433464057e-06.\n",
            "Epoch 29/70\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8s/step - accuracy: 0.8542 - loss: 1.3678\n",
            "Epoch 29: val_accuracy did not improve from 0.95238\n",
            "\n",
            "Epoch 29: ReduceLROnPlateau reducing learning rate to 3.5745819104704424e-07.\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 10s/step - accuracy: 0.8549 - loss: 1.3680 - val_accuracy: 0.9048 - val_loss: 1.3462 - learning_rate: 3.5746e-07\n",
            "Epoch 30: setting learning rate to 3.7363132635474363e-07\n",
            "\n",
            "Epoch 30: LearningRateScheduler setting learning rate to 3.7363132635474363e-07.\n",
            "Epoch 30/70\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8s/step - accuracy: 0.9319 - loss: 1.2590\n",
            "Epoch 30: val_accuracy did not improve from 0.95238\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 10s/step - accuracy: 0.9311 - loss: 1.2610 - val_accuracy: 0.8730 - val_loss: 1.3543 - learning_rate: 3.7363e-07\n",
            "Epoch 31: setting learning rate to 1e-07\n",
            "\n",
            "Epoch 31: LearningRateScheduler setting learning rate to 1e-07.\n",
            "Epoch 31/70\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8s/step - accuracy: 0.9408 - loss: 1.2769\n",
            "Epoch 31: val_accuracy did not improve from 0.95238\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 11s/step - accuracy: 0.9394 - loss: 1.2786 - val_accuracy: 0.8730 - val_loss: 1.3623 - learning_rate: 1.0000e-07\n",
            "Epoch 32: setting learning rate to 3.7363132635474363e-07\n",
            "\n",
            "Epoch 32: LearningRateScheduler setting learning rate to 3.7363132635474363e-07.\n",
            "Epoch 32/70\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8s/step - accuracy: 0.8779 - loss: 1.3436\n",
            "Epoch 32: val_accuracy did not improve from 0.95238\n",
            "\n",
            "Epoch 32: ReduceLROnPlateau reducing learning rate to 1.1208940122742205e-07.\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 11s/step - accuracy: 0.8784 - loss: 1.3436 - val_accuracy: 0.8730 - val_loss: 1.3702 - learning_rate: 1.1209e-07\n",
            "Epoch 33: setting learning rate to 1.1915273433464057e-06\n",
            "\n",
            "Epoch 33: LearningRateScheduler setting learning rate to 1.1915273433464057e-06.\n",
            "Epoch 33/70\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8s/step - accuracy: 0.9115 - loss: 1.3398\n",
            "Epoch 33: val_accuracy did not improve from 0.95238\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 10s/step - accuracy: 0.9112 - loss: 1.3398 - val_accuracy: 0.8730 - val_loss: 1.3810 - learning_rate: 1.1915e-06\n",
            "Epoch 34: setting learning rate to 2.5447270110570754e-06\n",
            "\n",
            "Epoch 34: LearningRateScheduler setting learning rate to 2.5447270110570754e-06.\n",
            "Epoch 34/70\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8s/step - accuracy: 0.8949 - loss: 1.3480\n",
            "Epoch 34: val_accuracy did not improve from 0.95238\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 10s/step - accuracy: 0.8953 - loss: 1.3466 - val_accuracy: 0.8730 - val_loss: 1.3927 - learning_rate: 2.5447e-06\n",
            "Epoch 35: setting learning rate to 4.4184043907520864e-06\n",
            "\n",
            "Epoch 35: LearningRateScheduler setting learning rate to 4.4184043907520864e-06.\n",
            "Epoch 35/70\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8s/step - accuracy: 0.8934 - loss: 1.3306\n",
            "Epoch 35: val_accuracy did not improve from 0.95238\n",
            "\n",
            "Epoch 35: ReduceLROnPlateau reducing learning rate to 1.3255213161755818e-06.\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 10s/step - accuracy: 0.8925 - loss: 1.3327 - val_accuracy: 0.8730 - val_loss: 1.4078 - learning_rate: 1.3255e-06\n",
            "Epoch 36: setting learning rate to 6.792031080967281e-06\n",
            "\n",
            "Epoch 36: LearningRateScheduler setting learning rate to 6.792031080967281e-06.\n",
            "Epoch 36/70\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8s/step - accuracy: 0.8764 - loss: 1.3558\n",
            "Epoch 36: val_accuracy did not improve from 0.95238\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 10s/step - accuracy: 0.8769 - loss: 1.3562 - val_accuracy: 0.8730 - val_loss: 1.4162 - learning_rate: 6.7920e-06\n",
            "Epoch 36: early stopping\n",
            "Restoring model weights from the end of the best epoch: 26.\n",
            "Tri-model hybrid with cosine LR training complete. Validation accuracy: 95.24%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XAIFmtfKuMpT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}